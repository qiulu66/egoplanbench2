<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="EgoPlan-Bench2: A Planning Benchmark for Multi-modal Large Language Models in Diverse Real-World Scenarios">
  <meta name="keywords" content="MLLMs, Benchmark, Human-level planning, Egocentric perspective">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>EgoPlan-Bench2: A Planning Benchmark for Multi-modal Large Language Models in Diverse Real-World Scenarios</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="icon" href="./static/images/icon.png">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">

  
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <!-- <script src="https://assets.crowd.aws/crowd-html-elements.js"></script> -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">






  <style>
    /* .section {
      padding: 3rem 1.5rem;
    }

    .container {
      max-width: 800px;
    }

    #video-container {
      margin-bottom: 2rem;
    }

    #question-container {
      margin-bottom: 2rem;
    }

    .buttons {
      display: flex;
      justify-content: space-between;
    }

    .button.is-primary {
      background-color: #3273dc;
      border-color: transparent;
      color: #fff;
      transition: background-color 0.3s ease;
    }

    .button.is-primary:hover {
      background-color: #275ab0;
      border-color: transparent;
    }

    .title img {
      margin-right: 0.5rem;
    }

    .select {
      width: 100%;
      margin-top: 1rem;
    } */

    /* Hide the "Previewing Answers Submitted by Workers" message */
    crowd-alert {
      display: none !important;
    }
  </style>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <div style="display: flex; align-items: center; justify-content: center;">
            <!-- <img src="./static/image/worldevallogo.png" style="width:6em;vertical-align: middle" alt="Logo"/>  -->
            <h1 class="title is-1 publication-title" style="display: inline-block;">EgoPlan-Bench2: A Planning Benchmark for Multi-modal Large Language Models in Diverse Real-World Scenarios</h1>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="">Lu Qiu</a><sup style="color: #FFB6C1;">1,2</sup>,</span>
            <span class="author-block">
              <a href="">Yuying Ge</a><sup style="color: #ADD8E6;">†,2</sup>,</span>
            <span class="author-block">
              <a href="">Yixiao Ge</a><sup style="color: #FFB6C1;">2</sup>,</span>
            <span class="author-block">
              <a href="">Yi Chen</a><sup style="color: #FFB6C1;">1,2</sup>,</span>
            <span class="author-block">
              <a href="">Xihui Liu</a><sup style="color: #ADD8E6;">†,1</sup>,</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup style="color: #FFB6C1;">1</sup>The University of Hong Kong, Hong Kong,</span>
            <span class="author-block"><sup style="color: #ADD8E6;">2</sup>ARC Lab, Tencent PCG, Shenzhen,</span>
          </div>
          <!-- <br>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><b style="color:#e08ba0; font-weight:normal"> <b>Under Review</b> </b></span>
          </div> -->
          <br>
          <div class="is-size-5 publication-authors">
            <span class="author-block">†Corresponding to:</span>
            <span class="author-block"><a href="mailto:xhe89@ucsc.edu">xhe89@ucsc.edu</a>,</span>
            <span class="author-block"><a href="mailto:xwang366@ucsc.edu">xwang366@ucsc.edu</a></span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->

              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://huggingface.co/datasets/qiulu66/EgoPlan-Bench2/tree/main/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-database"></i>
                  </span>
                  <span>dataset</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/qiulu66/EgoPlan-Bench2/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>

            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img id="overview" width="150%" src="./static/Images/task_overview.png">
      <h2 class="subtitle has-text-centered">
        <p style="font-family:Times New Roman"><b>Figure 1. EgoPlan-Bench2 focuses on the evaluation of task planning capacity. The model takes a partial video showing historical task progress, current observation image and a task goal expressed by language as input, and it is required to predict the most appropriate action to take next. </b></p>
      </h2>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            The rapid development of Multi-modal Large Language Models (MLLMs) which combine remarkable comprehension and generalization capacities has highlighted their potential ways to Artificial General Intelligence (AGI). A key milestone in AGI is achieving human-level task planning capabilities, which is essential for managing everyday human activities. This capability empowers models to make informed decisions in intricate environments, assisting humans in addressing a broad range of real-world challenges. Despite the notable progress within the realm of MLLMs, questions still remains: how effectively do MLLMs perform in real-world planning tasks, and how far are MLLMs from human-level task planners?
          </p>
          <p>
            In the quest for answering these questions, we introduce <b>EgoPlan-Bench2</b>, a comprehensive benchmark designed to evaluate MLLMs across diverse real-world planning tasks. EgoPlan-Bench2 is built upon the principles of first-person perspective and an extremely rich set of real-world tasks spanning 4 key domains and 24 fine-grained scenarios in human life, with a focus on evaluating models' planning abilities. We evaluate a wide range of MLLMs and observe that they still face substantial challenges, underscoring the need for considerable enhancements to attain human-level planning proficiency. To compensate the deficiency of the model and foster further improvements, we develop diverse prompts tailored to the characteristics of planning tasks, thereby augmenting the performance of GPT-4V on EgoPlan-Bench2 in a train-free manner.
          </p>
          <p>
            This repository describes the usage of our proposed EgoPlan-Bench2, and provides the corresponding codes for benchmarking MLLMs and enhancing GPT-4V's performance by prompting and CoT. Welcome to evaluate your models and explore methods to enhance the models' EgoPlan capabilities on our benchmark!
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-five-fifths">
        <h2 class="title is-3"><img id="painting_icon" width="5%" src="https://cdn-icons-png.flaticon.com/512/5379/5379860.png"> Dataset Statistics </h2> 
      </div>
    </div>

        <div class="columns is-centered has-text-centered">
          <div class="column is-six-fifths">  
            <img id="dataset" width="100%" src="./static/Images/data_statistic_1.png">
            <h3 class="subtitle has-text-centered">
              <p style="font-family:Times New Roman"><b>Figure 2. (Left) Video categories of different scenarios. EgoPlan-Bench2 covers 4 major domains and 24 fine-grained scenarios. (Right) Video length distribution and QA scenario distribution. Our benchmark has a full spectrum of video duration, ranging from a few seconds to five minutes. </b></p>
            </h3>   
        </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-five-fifths">
        <h2 class="title is-3"><img id="painting_icon" width="5%" src="https://cdn-icons-png.flaticon.com/512/5379/5379860.png"> Study on MLLMs Performance </h2> 
      </div>
    </div>

        <div class="columns is-centered has-text-centered">
          <div class="column is-six-fifths">  
            <img id="model_performance_table" width="100%" src="./static/Images/model_performance.jpg">
            <h3 class="subtitle has-text-centered">
              <p style="font-family:Times New Roman"><b>Figure 3. Models' performance across different scenarios and video lengths. </b></p>
            </h3>
            <img id="model_performance_scenarios" width="100%" src="./static/Images/results_24scenarios.png">
            <h3 class="subtitle has-text-centered">
              <p style="font-family:Times New Roman"><b>Figure 4. The accuracy of 21 MLLMs across the 4 main domains in human life. </b></p>
            </h3>   
        </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-five-fifths">
        <h2 class="title is-3"><img id="painting_icon" width="5%" src="https://cdn-icons-png.flaticon.com/512/5379/5379860.png"> Enhancing Human-Level Planning by Prompting </h2> 
      </div>
    </div>

        <div class="columns is-centered has-text-centered">
          <div class="column is-six-fifths">  
            <img id="model_performance_table" width="100%" src="./static/Images/cot.png">
            <h3 class="subtitle has-text-centered">
              <p style="font-family:Times New Roman"><b>Figure 5. We integrate Action-seq-GPT and BoundingBox-object prompts with CoT reasoning to enhance GPT-4V performance on EgoPlan-Bench2. These two prompts have been demonstrated to be effective in facilitating planning tasks, and incorporating voting mechanism further strengthens GPT-4V planning capability. </b></p>
            </h3>
        </div>
  </div>
</section>






<!-- <section class="section" id="examples">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-five-fifths">
        <h2 class="title is-3"><img id="painting_icon" width="5%" src="https://cdn-icons-png.flaticon.com/512/5379/5379860.png"> Examples</h2>
      </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-six-fifths">
        <div id="video-container">
          <video id="example-video" width="100%" height="315" controls>
            <source id="video-source" src="" type="video/mp4">
          </video>
        </div>

        <div id="question-container">
          <p id="question"></p>
          <select id="options" required=""></select>
        </div>

        <div class="buttons">
          <button id="prev-button" class="button is-primary">Previous</button>
          <button id="next-button" class="button is-primary">Next</button>
        </div>
      </div>
    </div>
  </div>
</section> -->




<!--section class="section" id="examples">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3">
          <img id="painting_icon" width="5%" src="https://cdn-icons-png.flaticon.com/512/5379/5379860.png" alt="Painting Icon">
          EgoPlan-Bench2 Examples
        </h2>
      </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <div id="video-container" class="box">
          <video id="example-video" class="is-fullwidth" controls>
            <source id="video-source" src="" type="video/mp4">
          </video>

          <p class="has-text-weight-bold" style="color: #4682b4;">Discipline: <span id="discipline" style="color: #4682b4;"></span></p>
          <p class="has-text-weight-bold" style="color: #ff69b4;">Subdiscipline: <span id="subdiscipline" style="color: #ff69b4;"></span></p>
          <p class="has-text-weight-bold" style="color: #66cdaa;">Question: <span id="question" style="color: #66cdaa;"></span></p>
          <div class="select is-fullwidth" style="margin-top: 1rem;">
            <select name="video-question-answer" id="options" required="">
            </select>
          </div>
        </div>
      </div>
    </div>
  </div>
</section -->

<section class="section" id="examples">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3">
          <img id="painting_icon" width="5%" src="https://cdn-icons-png.flaticon.com/512/5379/5379860.png" alt="Painting Icon">
          EgoPlan-Bench2 Examples
        </h2>
      </div>
    </div>

    <!-- 使用columns布局展示两个box在同一行 -->
    <div class="columns is-centered has-text-centered">
      <!-- 第一个box -->
      <div class="column is-half">
        <div id="video-container-1" class="box">
          <video id="example-video-1" class="is-fullwidth" controls>
            <source id="video-source-1" src="./Videos/d405ceed-68da-4e50-a0ef-5d2995a94e5d_QA-139.mp4" type="video/mp4">
          </video>

          <p class="has-text-weight-bold" style="color: #4682b4;">Scenario: Work - lab work<span id="discipline-1" style="color: #4682b4;"></span></p>
          <p class="has-text-weight-bold" style="color: #ff69b4;">Task goal: arrange seedlings on the tray<span id="subdiscipline-1" style="color: #ff69b4;"></span></p>
          <p class="has-text-weight-bold" style="color: #66cdaa;">Options: <b>close marker pen</b>, arrange seedlings on tray, pick seedling tray, turn tray
            <span id="question-1" style="color: #66cdaa;"></span></p>
          <div class="select is-fullwidth" style="margin-top: 1rem;">
            <select name="video-question-answer" id="options-1" required="">
            </select>
          </div>
        </div>
      </div>

      <!-- 第二个box -->
      <div class="column is-half">
        <div id="video-container-2" class="box">
          <video id="example-video-2" class="is-fullwidth" controls>
            <source id="video-source-2" src="" type="video/mp4">
          </video>

          <p class="has-text-weight-bold" style="color: #4682b4;">Discipline: <span id="discipline-2" style="color: #4682b4;"></span></p>
          <p class="has-text-weight-bold" style="color: #ff69b4;">Subdiscipline: <span id="subdiscipline-2" style="color: #ff69b4;"></span></p>
          <p class="has-text-weight-bold" style="color: #66cdaa;">Question: <span id="question-2" style="color: #66cdaa;"></span></p>
          <div class="select is-fullwidth" style="margin-top: 1rem;">
            <select name="video-question-answer" id="options-2" required="">
            </select>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>




<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
      @article{he2024mmworld,
        title   = {},
        author  = {},
        year    = {2024},
        journal = {}
      }
    </code></pre>
  </div>
</section>




<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is adapted from <a rel="license"
            href="https://github.com/MMWorld-bench/MMWorld-bench.github.io/">MMWorld-bench</a>, licensed under a Creative Commons Attribution-ShareAlike 4.0 International License.
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
        </div>
      </div>
    </div>
  </div>

</footer>





<script>
  let data = [];
  let currentIndex = 0;
  const videoUrlPrefix = "https://videounderstanding.s3.us-east-2.amazonaws.com/";

  function loadCSV() {
    $.ajax({
      type: "GET",
      url: "./static/webdemo_data.csv",
      dataType: "text",
      success: function(response) {
        data = $.csv.toObjects(response);
        updateContent();
      }
    });
  }

  function updateContent() {
    if (data.length > 0 && currentIndex >= 0 && currentIndex < data.length) {
      const currentData = data[currentIndex];
      const videoUrl = videoUrlPrefix + currentData.video_url;
      $('#video-source').attr('src', videoUrl);
      $('#example-video')[0].load();
      $('#question').text(currentData.question);
      $('#discipline').text(currentData.domain);
      $('#subdiscipline').text(currentData.subdomain);
      const options = [currentData.option_a, currentData.option_b, currentData.option_c, currentData.option_d];
      $('#options').empty();
      options.forEach(option => {
        $('#options').append(`<option value="${option}">${option}</option>`);
      });
    }
  }

  $('#next-button').on('click', function() {
    if (currentIndex < data.length - 1) {
      currentIndex++;
      updateContent();
    }
  });

  $('#prev-button').on('click', function() {
    if (currentIndex > 0) {
      currentIndex--;
      updateContent();
    }
  });

  $(document).ready(function() {
    loadCSV();
    
    const observer = new MutationObserver(() => {
      const alertElement = document.querySelector('crowd-form').shadowRoot.querySelector('crowd-alert').shadowRoot.querySelector('awsui-alert');
      if (alertElement) {
        alertElement.style.display = 'none';
      }
    });
    
    observer.observe(document.querySelector('crowd-form').shadowRoot, { childList: true, subtree: true });
  });
</script>


<!-- Additional libraries for parsing CSV -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-csv/1.0.21/jquery.csv.min.js"></script>

</body>
</html>
